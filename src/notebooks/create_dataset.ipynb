{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = load_dataset('verifiers-for-code/CodePython-27k-multiple-plangen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d1.rename_column('code', 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['data_name', 'id', 'prompt', 'output', 'text', 'input', 'non_granular_plans_Llama-3-70B', 'granular_plans_Llama-3-70B', 'deepseek_plans_eval', 'deepseek_solution_eval', 'non_granular_plans_temp_0_dot_7_llama_3_70B', 'non_granular_plans_temp_0_llama_3_70B'],\n",
       "        num_rows: 27224\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4 = load_dataset(\"jtatman/combined_coder_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "d4 = d4.rename_column('instruction', 'prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'prompt', 'input'],\n",
       "        num_rows: 559515\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert datasets to pandas DataFrames\n",
    "df1 = d1['train'].to_pandas()\n",
    "df4 = d4['train'].to_pandas()\n",
    "\n",
    "# Create a new DataFrame with only 'prompt' and 'output' columns from all datasets\n",
    "combined_df = pd.concat([\n",
    "    df1[['prompt', 'output']],\n",
    "    df4[['prompt', 'output']]\n",
    "], ignore_index=True)\n",
    "\n",
    "# Convert the combined DataFrame back to a dataset\n",
    "combined_dataset = Dataset.from_pandas(combined_df)\n",
    "\n",
    "# Create a DatasetDict\n",
    "combined_dataset_dict = DatasetDict({'train': combined_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'output'],\n",
       "        num_rows: 586739\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(dataset_dict):\n",
    "    # Get the 'train' split\n",
    "    train_dataset = dataset_dict['train']\n",
    "    \n",
    "    # Convert to pandas DataFrame\n",
    "    df = train_dataset.to_pandas()\n",
    "    \n",
    "    # Remove duplicates based on 'prompt' column\n",
    "    df_unique = df.drop_duplicates(subset=['prompt'], ignore_index=True)\n",
    "    \n",
    "    # Convert back to Dataset\n",
    "    unique_dataset = Dataset.from_pandas(df_unique)\n",
    "    \n",
    "    # Create a new DatasetDict with the unique dataset\n",
    "    return DatasetDict({'train': unique_dataset})\n",
    "\n",
    "# Apply the function to your dataset\n",
    "unique_combined_dataset_dict = remove_duplicates(combined_dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'output'],\n",
       "        num_rows: 521593\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_combined_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 261/261 [00:01<00:00, 153.40ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 261/261 [00:00<00:00, 311.87ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:09<00:00,  4.84s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/verifiers-for-code/Combined-Python-520k/commit/52476d15044c9f9c8225673208f91db3572d84bd', commit_message='Upload dataset', commit_description='', oid='52476d15044c9f9c8225673208f91db3572d84bd', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_combined_dataset_dict.push_to_hub('verifiers-for-code/Combined-Python-520k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
