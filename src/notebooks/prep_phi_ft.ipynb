{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/miniconda3/envs/inference/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhinav/miniconda3/envs/inference/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"verifiers-for-code/tester3\", split='train')\n",
    "\n",
    "# Load the tokenizer for the chat template\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "def apply_template(example):\n",
    "    chat_prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are given the start of a function for a Python program. Your job is to produce a detailed plan. First, analyze and think, by using <thinking> XML tags, and then, produce a plan, in <plan> tags.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": example['input']},\n",
    "            {\"role\": \"assistant\", \"content\": example['structured_plans_Llama-3_1-70B']},\n",
    "        ],\n",
    "        tokenize=False\n",
    "    )\n",
    "    return {\"text\": chat_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 27224/27224 [00:05<00:00, 4938.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = dataset.map(apply_template)\n",
    "\n",
    "# Keep only the 'text' column\n",
    "processed_dataset = processed_dataset.remove_columns([col for col in processed_dataset.column_names if col != 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|system|>\\nYou are given the start of a function for a Python program. Your job is to produce a detailed plan. First, analyze and think, by using <thinking> XML tags, and then, produce a plan, in <plan> tags.<|end|>\\n<|user|>\\ndef add_numbers(num1: int | float, num2: int | float) -> int | float:\\n    \"\"\"\\n    Return the sum of two numbers.\\n    \\n    >>> add_numbers(5, 3)\\n    8\\n    >>> add_numbers(-5, 3)\\n    -2\\n    >>> add_numbers(5.5, 3.2)\\n    8.7\\n    \"\"\"<|end|>\\n<|assistant|>\\n<thinking>\\nThe problem at hand is to implement a simple function `add_numbers` that takes two numbers as input and returns their sum. The input numbers can be either integers or floating-point numbers. Let\\'s break it down:\\n\\n1. Main objective: The function should calculate the sum of two numbers.\\n2. Key considerations:\\n   a. Input types: Both integer and floating-point numbers are allowed.\\n   b. Output type: The result should be of the same type as the inputs (integer or float).\\n3. Key steps:\\n   a. Define the function with two parameters, num1 and num2.\\n   b. Use the built-in addition operator (+) to calculate the sum of num1 and num2.\\n   c. Return the calculated sum.\\n4. Edge cases and special considerations:\\n   a. Handling non-numeric inputs: Not explicitly mentioned, but we should consider what happens if the inputs are not numbers (e.g., strings, booleans).\\n   b. Overflow: In extreme cases, the sum of two large numbers might exceed the maximum limit for integers or floats, but this is a rare edge case.\\n\\n</thinking>\\n\\n<plan>\\nVariable Initialization:\\n- num1: int | float (first number)\\n- num2: int | float (second number)\\n\\nObjective: Calculate the sum of two numbers.\\n\\nImplementation:\\nCalculations:\\n- Calculate the sum of num1 and num2 using the addition operator (+)\\nReturn:\\n- Return the calculated sum\\n\\nEdge Cases:\\nInvalid Inputs:\\n- Non-numeric inputs: Not handled in the provided solution, but could be considered for robustness\\n- Overflow: Not handled, but rare and typically not a concern for most use cases\\nBoundary Conditions:\\n- Extreme values (e.g., very large or very small numbers): Should work as expected, but might be affected by precision or overflow issues\\nSpecial Cases:\\n- Adding zero: Should return the other number (identity element for addition)\\n- Adding two identical numbers: Should return twice the original number\\n</plan><|end|>\\n<|endoftext|>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 28/28 [00:00<00:00, 106.18ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/verifiers-for-code/structured_ft_27k_phi3/commit/37dc38983b9a43f5972bdd03f1ad7cb79124f373', commit_message='Upload dataset', commit_description='', oid='37dc38983b9a43f5972bdd03f1ad7cb79124f373', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_dataset.push_to_hub('verifiers-for-code/structured_ft_27k_phi3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
