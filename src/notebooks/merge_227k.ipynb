{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= load_dataset('verifiers-for-code/merged_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = load_dataset('verifiers-for-code/CodePython-27k-multiple-plangen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['problem', 'solution', '70B_plans'],\n",
       "        num_rows: 200000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['data_name', 'id', 'prompt', 'code', 'text', 'input', 'non_granular_plans_Llama-3-70B', 'granular_plans_Llama-3-70B', 'deepseek_plans_eval', 'deepseek_solution_eval', 'non_granular_plans_temp_0_dot_7_llama_3_70B', 'non_granular_plans_temp_0_llama_3_70B'],\n",
       "        num_rows: 27224\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.rename_column('input', 'problem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.rename_column('code', 'solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.rename_column('non_granular_plans_Llama-3-70B', '70B_plans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['data_name', 'id', 'prompt', 'solution', 'text', 'problem', '70B_plans', 'granular_plans_Llama-3-70B', 'deepseek_plans_eval', 'deepseek_solution_eval', 'non_granular_plans_temp_0_dot_7_llama_3_70B', 'non_granular_plans_temp_0_llama_3_70B'],\n",
       "        num_rows: 27224\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['problem', 'solution', '70B_plans'],\n",
      "        num_rows: 227224\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data2_selected = data2['train'].select_columns(['problem', 'solution', '70B_plans'])\n",
    "\n",
    "# Concatenate data1 and the selected columns from data2\n",
    "merged_dataset = concatenate_datasets([data1['train'], data2_selected])\n",
    "\n",
    "# Create a new DatasetDict with the merged dataset\n",
    "merged_data = DatasetDict({'train': merged_dataset})\n",
    "\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 114/114 [00:00<00:00, 172.02ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 114/114 [00:01<00:00, 97.80ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 2/2 [00:07<00:00,  3.99s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/verifiers-for-code/merged-227k/commit/9153a1067761f39d53d0be36e9fa83779e187a64', commit_message='Upload dataset', commit_description='', oid='9153a1067761f39d53d0be36e9fa83779e187a64', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.push_to_hub('verifiers-for-code/merged-227k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
